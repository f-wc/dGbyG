{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8014dae",
   "metadata": {},
   "source": [
    "# This script is used to train the MPNN_model for dGbyG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1fa662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dGbyG.data import TrainDataset\n",
    "\n",
    "from dGbyG.model import MPNN_model, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c006960c",
   "metadata": {},
   "source": [
    "# 1. Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6e144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training data as pd.DataFrame\n",
    "train_data_path = '../data/TrainingData.csv'\n",
    "TrainingData_df = pd.read_csv(train_data_path)\n",
    "equation = TrainingData_df.loc[:, 'reaction'].to_numpy()\n",
    "standard_dG_prime = TrainingData_df.loc[:, 'standard_dg_prime'].to_numpy()\n",
    "\n",
    "# compute the weight for each data point\n",
    "mean_std = TrainingData_df.loc[:,'std'].mean()\n",
    "Scale = []\n",
    "for n, sem in zip(TrainingData_df.loc[:,'n'], TrainingData_df.loc[:,'SEM']):\n",
    "    if np.isnan(sem):\n",
    "        scale = mean_std\n",
    "    else:\n",
    "        scale = (sem**2 + mean_std**2/n)**0.5\n",
    "    Scale.append(scale)\n",
    "Scale = np.array(Scale)\n",
    "weight = 1/np.array(Scale)/np.median(Scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fee435f",
   "metadata": {},
   "source": [
    "# 2. Set super parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16727873",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet = TrainDataset(equations=equation, dGs=standard_dG_prime, weights=weight)\n",
    "\n",
    "# four super parameters for the model\n",
    "atom_feature_size = TrainSet[0].x.size(1)\n",
    "bond_feature_size = TrainSet[0].edge_attr.size(1)\n",
    "embedding_dim = 256\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3811bdc9",
   "metadata": {},
   "source": [
    "# 3. Set the directory path to save the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c7e066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_folder = f'../models/mpnn_A{atom_feature_size}_B{bond_feature_size}_E{embedding_dim}_L{num_layers}'\n",
    "\n",
    "if not os.path.isdir(model_weights_folder):\n",
    "    os.makedirs(model_weights_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a933c9",
   "metadata": {},
   "source": [
    "# 4. Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfaa6714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on: cuda:0\n",
      "2025-09-11 00:46:13 start preparing data\n",
      "2025-09-11 00:46:14 start training\n",
      "Training |===================================================================================================| Done!\n",
      "2025-09-11 00:46:45 training have done\n",
      "0 done\n",
      "train on: cuda:0\n",
      "2025-09-11 00:46:46 start preparing data\n",
      "2025-09-11 00:46:47 start training\n",
      "Training |===================================================================================================| Done!\n",
      "2025-09-11 00:47:16 training have done\n",
      "1 done\n",
      "train on: cuda:0\n",
      "2025-09-11 00:47:17 start preparing data\n",
      "2025-09-11 00:47:19 start training\n",
      "Training |===================================================================================================| Done!\n",
      "2025-09-11 00:47:49 training have done\n",
      "2 done\n",
      "train on: cuda:0\n",
      "2025-09-11 00:47:50 start preparing data\n",
      "2025-09-11 00:47:51 start training\n",
      "Training |===================================================================================================| Done!\n",
      "2025-09-11 00:48:21 training have done\n",
      "3 done\n",
      "train on: cuda:0\n",
      "2025-09-11 00:48:22 start preparing data\n",
      "2025-09-11 00:48:23 start training\n",
      "Training |===================================================================================================| Done!\n",
      "2025-09-11 00:48:53 training have done\n",
      "4 done\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "# Train the network N times (here N=100).\n",
    "N=5\n",
    "for n in range(N):\n",
    "    dG = standard_dG_prime + np.random.randn(standard_dG_prime.shape[0]) * Scale\n",
    "    TrainSet = TrainDataset(equations=equation, dGs=dG, weights=weight)\n",
    "\n",
    "    network = MPNN_model(atom_dim=atom_feature_size, bond_dim=bond_feature_size, emb_dim=embedding_dim, num_layer=num_layers)\n",
    "    trainer = Trainer()\n",
    "    trainer.network = network\n",
    "\n",
    "    loss_history, Result_df, i = trainer.train(TrainSet, epochs=9000, lr=1e-4, weight_decay=1e-6)\n",
    "    \n",
    "    torch.save(trainer.network.state_dict(), os.path.join(model_weights_folder, str(n)+'.pt'))\n",
    "    print(f'{n} done')\n",
    "\n",
    "print('All done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47d87b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dGbyG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
